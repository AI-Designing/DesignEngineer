# API keys are now managed via .env file for security
# See .env.example for required environment variables
freecad_api_url: "http://localhost:8080"

# FreeCAD Installation Configuration
# Priority: FREECAD_PATH env var > appimage_path > lib_path/mod_path > auto-detect
freecad:
  # Path to FreeCAD AppImage file
  # Example: "/home/user/Downloads/FreeCAD_1.0.1-conda-Linux-x86_64-py311.AppImage"
  # Can be overridden by FREECAD_PATH environment variable
  # Set via FREECAD_APPIMAGE_PATH env var or leave empty for auto-detection
  appimage_path: ""

  # Alternative: Explicit library and module paths (for custom installations)
  # These are auto-detected from AppImage, only set for non-standard installs
  # Example lib_path: "/usr/lib/freecad/lib"
  # Example mod_path: "/usr/lib/freecad/Mod"
  lib_path: ""
  mod_path: ""

  # Execution mode: "appimage", "subprocess", or "direct"
  # Auto-detected based on installation type
  execution_mode: "auto"

# Online code generation provider (replaces local DeepSeek R1 via Ollama)
# Default model: google/gemini-2.0-flash
# Override with env var: CODEGEN_MODEL=openai/gpt-4o
# Requires: GOOGLE_API_KEY  (or OPENAI_API_KEY for gpt-4o fallback)
online_codegen:
  enabled: true
  model: "google/gemini-2.0-flash"
  fallback_model: "openai/gpt-4o"
  temperature: 0.1
  max_tokens: 8192
  timeout: 120

# DeepSeek R1 Local Configuration (legacy â€“ disabled by default)
# Set enabled: true only if you are running Ollama locally with deepseek-r1:14b
deepseek:
  enabled: false
  host: "localhost"
  port: 11434
  model_name: "deepseek-r1:14b"
  timeout: 600
  max_tokens: 8192
  temperature: 0.1
  top_p: 0.95
  reasoning_enabled: true
  stream: true
  fallback_to_gemini: true

redis:
  host: "localhost"
  port: 6379
  db: 0

command_timeout: 30
log_level: "INFO"

# Enhanced Complex Generator Settings
enhanced_generator:
  use_deepseek: true
  quality_targets:
    geometric_accuracy: 0.9
    design_consistency: 0.85
    aesthetic_quality: 0.8
    manufacturability: 0.9
    performance_score: 0.85

  pattern_learning:
    enabled: true
    max_patterns: 1000
    similarity_threshold: 0.6

  quality_prediction:
    enabled: true
    confidence_threshold: 0.7

# LLM agent model configuration (overrides llm/model_config.py defaults)
llm_agents:
  planner:
    primary: "anthropic/claude-3-5-sonnet-20241022"
    fallback: "google/gemini-pro"
    temperature: 0.3
    max_tokens: 4096
  generator:
    primary: "google/gemini-2.0-flash"
    fallback: "openai/gpt-4o"
    temperature: 0.1
    max_tokens: 8192
  validator:
    primary: "anthropic/claude-3-5-sonnet-20241022"
    fallback: "openai/gpt-4o"
    temperature: 0.3
    max_tokens: 2048
  orchestrator:
    primary: "anthropic/claude-3-5-sonnet-20241022"
    fallback: "google/gemini-pro"
    temperature: 0.4
    max_tokens: 2048
